{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook based on kernel GTendolkar to improve parameters and try to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "9b38bcf7-3bff-4220-98ae-9fd884e8628a",
    "_uuid": "e0f1b00f6c3887c3f37687d60a22ac163bce8853",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.952120e+05</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.438036e+05</td>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>1.358943</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.293678e+05</td>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>0.664594</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.493311</td>\n",
       "      <td>1.350642</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.719915e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.435475e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.115549e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target      ps_ind_01  ps_ind_02_cat  \\\n",
       "count  5.952120e+05  595212.000000  595212.000000  595212.000000   \n",
       "mean   7.438036e+05       0.036448       1.900378       1.358943   \n",
       "std    4.293678e+05       0.187401       1.983789       0.664594   \n",
       "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
       "25%    3.719915e+05       0.000000       0.000000       1.000000   \n",
       "50%    7.435475e+05       0.000000       1.000000       1.000000   \n",
       "75%    1.115549e+06       0.000000       3.000000       2.000000   \n",
       "max    1.488027e+06       1.000000       7.000000       4.000000   \n",
       "\n",
       "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        4.423318       0.416794       0.405188       0.393742   \n",
       "std         2.699902       0.493311       1.350642       0.488579   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         4.000000       0.000000       0.000000       0.000000   \n",
       "75%         6.000000       1.000000       0.000000       1.000000   \n",
       "max        11.000000       1.000000       6.000000       1.000000   \n",
       "\n",
       "       ps_ind_07_bin  ps_ind_08_bin       ...           ps_calc_11  \\\n",
       "count  595212.000000  595212.000000       ...        595212.000000   \n",
       "mean        0.257033       0.163921       ...             5.441382   \n",
       "std         0.436998       0.370205       ...             2.332871   \n",
       "min         0.000000       0.000000       ...             0.000000   \n",
       "25%         0.000000       0.000000       ...             4.000000   \n",
       "50%         0.000000       0.000000       ...             5.000000   \n",
       "75%         1.000000       0.000000       ...             7.000000   \n",
       "max         1.000000       1.000000       ...            19.000000   \n",
       "\n",
       "          ps_calc_12     ps_calc_13     ps_calc_14  ps_calc_15_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000   595212.000000   \n",
       "mean        1.441918       2.872288       7.539026        0.122427   \n",
       "std         1.202963       1.694887       2.746652        0.327779   \n",
       "min         0.000000       0.000000       0.000000        0.000000   \n",
       "25%         1.000000       2.000000       6.000000        0.000000   \n",
       "50%         1.000000       3.000000       7.000000        0.000000   \n",
       "75%         2.000000       4.000000       9.000000        0.000000   \n",
       "max        10.000000      13.000000      23.000000        1.000000   \n",
       "\n",
       "       ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000   \n",
       "mean         0.627840        0.554182        0.287182        0.349024   \n",
       "std          0.483381        0.497056        0.452447        0.476662   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        1.000000        0.000000        0.000000   \n",
       "75%          1.000000        1.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_20_bin  \n",
       "count   595212.000000  \n",
       "mean         0.153318  \n",
       "std          0.360295  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as scp\n",
    "import csv\n",
    "\n",
    "train_master = pd.read_csv('./input/train.csv')\n",
    "test_master = pd.read_csv('./input/test.csv')\n",
    "train_master.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "d93969af-c4fb-420e-b84c-1d3c5d9c780b",
    "_uuid": "ca71b128aa4a196a66ed81a22a6eacb058f2128c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(y, pred):\n",
    "    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    g = 2 * metrics.auc(fpr, tpr) -1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "4723bf6d-58ac-4868-b51c-851227402497",
    "_uuid": "83c29704217edc94c706d70511dc70796531461d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 10\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "85081958-bd60-4f5b-bb60-c259169e682f",
    "_uuid": "51e135c9bb24bc36fd2ebf265e7db31fa85f4ba8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def encode_cat_features(train_df, test_df, cat_cols, target_col_name, smoothing=1):\n",
    "    prior = train_df[target_col_name].mean()\n",
    "    probs_dict = {}\n",
    "    for c in cat_cols:\n",
    "        probs = train_df.groupby(c, as_index=False)[target_col_name].mean()\n",
    "        probs['counts'] = train_df.groupby(c, as_index=False)[target_col_name].count()[[target_col_name]]\n",
    "        probs['smoothing'] = 1 / (1 + np.exp(-(probs['counts'] - 1) / smoothing))\n",
    "        probs['enc'] = prior * (1 - probs['smoothing']) + probs['target'] * probs['smoothing']\n",
    "        probs_dict[c] = probs[[c,'enc']]\n",
    "    return probs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "e3d9ecd6-1933-4465-b02d-82735784b75e",
    "_uuid": "7de0ffddadadbd0f29276cc12e5051fd55816195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.6295\n",
      "[100]\tvalid_0's auc: 0.634919\n",
      "[150]\tvalid_0's auc: 0.636065\n",
      "[200]\tvalid_0's auc: 0.63728\n",
      "[250]\tvalid_0's auc: 0.637661\n",
      "[300]\tvalid_0's auc: 0.637865\n",
      "[350]\tvalid_0's auc: 0.637623\n",
      "[400]\tvalid_0's auc: 0.637589\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's auc: 0.637922\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.632789\n",
      "[100]\tvalid_0's auc: 0.636587\n",
      "[150]\tvalid_0's auc: 0.638363\n",
      "[200]\tvalid_0's auc: 0.638781\n",
      "[250]\tvalid_0's auc: 0.638731\n",
      "[300]\tvalid_0's auc: 0.638656\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.639014\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.63314\n",
      "[100]\tvalid_0's auc: 0.636723\n",
      "[150]\tvalid_0's auc: 0.638186\n",
      "[200]\tvalid_0's auc: 0.638789\n",
      "[250]\tvalid_0's auc: 0.638213\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's auc: 0.638813\n",
      "Fold  1 : 0.278339921\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.62469\n",
      "[100]\tvalid_0's auc: 0.634221\n",
      "[150]\tvalid_0's auc: 0.638842\n",
      "[200]\tvalid_0's auc: 0.640973\n",
      "[250]\tvalid_0's auc: 0.642675\n",
      "[300]\tvalid_0's auc: 0.644309\n",
      "[350]\tvalid_0's auc: 0.644835\n",
      "[400]\tvalid_0's auc: 0.645305\n",
      "[450]\tvalid_0's auc: 0.645462\n",
      "[500]\tvalid_0's auc: 0.645673\n",
      "[550]\tvalid_0's auc: 0.645646\n",
      "[600]\tvalid_0's auc: 0.645817\n",
      "[650]\tvalid_0's auc: 0.646025\n",
      "[700]\tvalid_0's auc: 0.646232\n",
      "[750]\tvalid_0's auc: 0.646108\n",
      "[800]\tvalid_0's auc: 0.646286\n",
      "[850]\tvalid_0's auc: 0.646054\n",
      "Early stopping, best iteration is:\n",
      "[784]\tvalid_0's auc: 0.646412\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.630527\n",
      "[100]\tvalid_0's auc: 0.639256\n",
      "[150]\tvalid_0's auc: 0.64316\n",
      "[200]\tvalid_0's auc: 0.645586\n",
      "[250]\tvalid_0's auc: 0.646837\n",
      "[300]\tvalid_0's auc: 0.647124\n",
      "[350]\tvalid_0's auc: 0.646934\n",
      "[400]\tvalid_0's auc: 0.646568\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's auc: 0.647165\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.631162\n",
      "[100]\tvalid_0's auc: 0.638305\n",
      "[150]\tvalid_0's auc: 0.64246\n",
      "[200]\tvalid_0's auc: 0.644415\n",
      "[250]\tvalid_0's auc: 0.645229\n",
      "[300]\tvalid_0's auc: 0.645939\n",
      "[350]\tvalid_0's auc: 0.645683\n",
      "[400]\tvalid_0's auc: 0.645828\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's auc: 0.645995\n",
      "Fold  2 : 0.295029257\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.621976\n",
      "[100]\tvalid_0's auc: 0.6317\n",
      "[150]\tvalid_0's auc: 0.635971\n",
      "[200]\tvalid_0's auc: 0.637526\n",
      "[250]\tvalid_0's auc: 0.638452\n",
      "[300]\tvalid_0's auc: 0.639476\n",
      "[350]\tvalid_0's auc: 0.640205\n",
      "[400]\tvalid_0's auc: 0.640726\n",
      "[450]\tvalid_0's auc: 0.640911\n",
      "[500]\tvalid_0's auc: 0.641089\n",
      "[550]\tvalid_0's auc: 0.641153\n",
      "[600]\tvalid_0's auc: 0.641195\n",
      "[650]\tvalid_0's auc: 0.64101\n",
      "Early stopping, best iteration is:\n",
      "[599]\tvalid_0's auc: 0.641231\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.627347\n",
      "[100]\tvalid_0's auc: 0.636414\n",
      "[150]\tvalid_0's auc: 0.638623\n",
      "[200]\tvalid_0's auc: 0.639847\n",
      "[250]\tvalid_0's auc: 0.640529\n",
      "[300]\tvalid_0's auc: 0.64063\n",
      "[350]\tvalid_0's auc: 0.640385\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's auc: 0.640824\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.632564\n",
      "[100]\tvalid_0's auc: 0.636813\n",
      "[150]\tvalid_0's auc: 0.639848\n",
      "[200]\tvalid_0's auc: 0.640166\n",
      "[250]\tvalid_0's auc: 0.640355\n",
      "[300]\tvalid_0's auc: 0.640517\n",
      "[350]\tvalid_0's auc: 0.641574\n",
      "[400]\tvalid_0's auc: 0.641633\n",
      "[450]\tvalid_0's auc: 0.64131\n",
      "[500]\tvalid_0's auc: 0.641926\n",
      "[550]\tvalid_0's auc: 0.641316\n",
      "[600]\tvalid_0's auc: 0.641192\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's auc: 0.641964\n",
      "Fold  3 : 0.284632166\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.635129\n",
      "[100]\tvalid_0's auc: 0.644333\n",
      "[150]\tvalid_0's auc: 0.647936\n",
      "[200]\tvalid_0's auc: 0.64998\n",
      "[250]\tvalid_0's auc: 0.650905\n",
      "[300]\tvalid_0's auc: 0.651688\n",
      "[350]\tvalid_0's auc: 0.65261\n",
      "[400]\tvalid_0's auc: 0.652747\n",
      "[450]\tvalid_0's auc: 0.653\n",
      "[500]\tvalid_0's auc: 0.653551\n",
      "[550]\tvalid_0's auc: 0.653535\n",
      "[600]\tvalid_0's auc: 0.653434\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid_0's auc: 0.653683\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.639382\n",
      "[100]\tvalid_0's auc: 0.647169\n",
      "[150]\tvalid_0's auc: 0.650215\n",
      "[200]\tvalid_0's auc: 0.65244\n",
      "[250]\tvalid_0's auc: 0.653282\n",
      "[300]\tvalid_0's auc: 0.654283\n",
      "[350]\tvalid_0's auc: 0.65473\n",
      "[400]\tvalid_0's auc: 0.654824\n",
      "[450]\tvalid_0's auc: 0.655212\n",
      "[500]\tvalid_0's auc: 0.655331\n",
      "[550]\tvalid_0's auc: 0.655223\n",
      "[600]\tvalid_0's auc: 0.655101\n",
      "Early stopping, best iteration is:\n",
      "[542]\tvalid_0's auc: 0.655577\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.646815\n",
      "[100]\tvalid_0's auc: 0.649384\n",
      "[150]\tvalid_0's auc: 0.651283\n",
      "[200]\tvalid_0's auc: 0.652822\n",
      "[250]\tvalid_0's auc: 0.654178\n",
      "[300]\tvalid_0's auc: 0.654708\n",
      "[350]\tvalid_0's auc: 0.654296\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's auc: 0.654878\n",
      "Fold  4 : 0.311504539\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.612979\n",
      "[100]\tvalid_0's auc: 0.622759\n",
      "[150]\tvalid_0's auc: 0.627183\n",
      "[200]\tvalid_0's auc: 0.629246\n",
      "[250]\tvalid_0's auc: 0.630129\n",
      "[300]\tvalid_0's auc: 0.630858\n",
      "[350]\tvalid_0's auc: 0.631364\n",
      "[400]\tvalid_0's auc: 0.631777\n",
      "[450]\tvalid_0's auc: 0.632267\n",
      "[500]\tvalid_0's auc: 0.632394\n",
      "[550]\tvalid_0's auc: 0.632667\n",
      "[600]\tvalid_0's auc: 0.632653\n",
      "[650]\tvalid_0's auc: 0.632453\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid_0's auc: 0.632761\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.617979\n",
      "[100]\tvalid_0's auc: 0.626476\n",
      "[150]\tvalid_0's auc: 0.630098\n",
      "[200]\tvalid_0's auc: 0.632369\n",
      "[250]\tvalid_0's auc: 0.632424\n",
      "[300]\tvalid_0's auc: 0.632619\n",
      "[350]\tvalid_0's auc: 0.633043\n",
      "[400]\tvalid_0's auc: 0.632929\n",
      "[450]\tvalid_0's auc: 0.632694\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's auc: 0.633258\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.620283\n",
      "[100]\tvalid_0's auc: 0.626852\n",
      "[150]\tvalid_0's auc: 0.630647\n",
      "[200]\tvalid_0's auc: 0.63194\n",
      "[250]\tvalid_0's auc: 0.632811\n",
      "[300]\tvalid_0's auc: 0.633215\n",
      "[350]\tvalid_0's auc: 0.633977\n",
      "[400]\tvalid_0's auc: 0.634261\n",
      "[450]\tvalid_0's auc: 0.634377\n",
      "[500]\tvalid_0's auc: 0.634477\n",
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's auc: 0.634554\n",
      "Fold  5 : 0.268560122\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.625132\n",
      "[100]\tvalid_0's auc: 0.633725\n",
      "[150]\tvalid_0's auc: 0.638004\n",
      "[200]\tvalid_0's auc: 0.639846\n",
      "[250]\tvalid_0's auc: 0.640821\n",
      "[300]\tvalid_0's auc: 0.641677\n",
      "[350]\tvalid_0's auc: 0.641941\n",
      "[400]\tvalid_0's auc: 0.642334\n",
      "[450]\tvalid_0's auc: 0.642387\n",
      "[500]\tvalid_0's auc: 0.642702\n",
      "[550]\tvalid_0's auc: 0.643077\n",
      "[600]\tvalid_0's auc: 0.643186\n",
      "[650]\tvalid_0's auc: 0.643185\n",
      "[700]\tvalid_0's auc: 0.642978\n",
      "Early stopping, best iteration is:\n",
      "[627]\tvalid_0's auc: 0.643303\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.628954\n",
      "[100]\tvalid_0's auc: 0.636771\n",
      "[150]\tvalid_0's auc: 0.640133\n",
      "[200]\tvalid_0's auc: 0.641426\n",
      "[250]\tvalid_0's auc: 0.641594\n",
      "[300]\tvalid_0's auc: 0.641557\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.641713\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.632978\n",
      "[100]\tvalid_0's auc: 0.637765\n",
      "[150]\tvalid_0's auc: 0.640388\n",
      "[200]\tvalid_0's auc: 0.642494\n",
      "[250]\tvalid_0's auc: 0.64287\n",
      "[300]\tvalid_0's auc: 0.642847\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's auc: 0.643128\n",
      "Fold  6 : 0.286870237\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.616468\n",
      "[100]\tvalid_0's auc: 0.627525\n",
      "[150]\tvalid_0's auc: 0.630207\n",
      "[200]\tvalid_0's auc: 0.631309\n",
      "[250]\tvalid_0's auc: 0.632382\n",
      "[300]\tvalid_0's auc: 0.63337\n",
      "[350]\tvalid_0's auc: 0.63412\n",
      "[400]\tvalid_0's auc: 0.634613\n",
      "[450]\tvalid_0's auc: 0.634913\n",
      "[500]\tvalid_0's auc: 0.635294\n",
      "[550]\tvalid_0's auc: 0.635351\n",
      "[600]\tvalid_0's auc: 0.635303\n",
      "Early stopping, best iteration is:\n",
      "[527]\tvalid_0's auc: 0.635495\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.621519\n",
      "[100]\tvalid_0's auc: 0.629967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's auc: 0.632496\n",
      "[200]\tvalid_0's auc: 0.634265\n",
      "[250]\tvalid_0's auc: 0.634668\n",
      "[300]\tvalid_0's auc: 0.634684\n",
      "[350]\tvalid_0's auc: 0.635409\n",
      "[400]\tvalid_0's auc: 0.635042\n",
      "[450]\tvalid_0's auc: 0.635445\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's auc: 0.635612\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.625632\n",
      "[100]\tvalid_0's auc: 0.630207\n",
      "[150]\tvalid_0's auc: 0.632658\n",
      "[200]\tvalid_0's auc: 0.633717\n",
      "[250]\tvalid_0's auc: 0.634727\n",
      "[300]\tvalid_0's auc: 0.635679\n",
      "[350]\tvalid_0's auc: 0.635942\n",
      "[400]\tvalid_0's auc: 0.635978\n",
      "[450]\tvalid_0's auc: 0.63565\n",
      "Early stopping, best iteration is:\n",
      "[355]\tvalid_0's auc: 0.636024\n",
      "Fold  7 : 0.272943927\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.6221\n",
      "[100]\tvalid_0's auc: 0.633107\n",
      "[150]\tvalid_0's auc: 0.637235\n",
      "[200]\tvalid_0's auc: 0.639263\n",
      "[250]\tvalid_0's auc: 0.640392\n",
      "[300]\tvalid_0's auc: 0.640832\n",
      "[350]\tvalid_0's auc: 0.641362\n",
      "[400]\tvalid_0's auc: 0.641584\n",
      "[450]\tvalid_0's auc: 0.641999\n",
      "[500]\tvalid_0's auc: 0.642047\n",
      "[550]\tvalid_0's auc: 0.642274\n",
      "[600]\tvalid_0's auc: 0.642637\n",
      "[650]\tvalid_0's auc: 0.642726\n",
      "[700]\tvalid_0's auc: 0.642827\n",
      "[750]\tvalid_0's auc: 0.642903\n",
      "[800]\tvalid_0's auc: 0.6429\n",
      "[850]\tvalid_0's auc: 0.642965\n",
      "[900]\tvalid_0's auc: 0.643092\n",
      "[950]\tvalid_0's auc: 0.643001\n",
      "[1000]\tvalid_0's auc: 0.64296\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.627486\n",
      "[100]\tvalid_0's auc: 0.637162\n",
      "[150]\tvalid_0's auc: 0.639908\n",
      "[200]\tvalid_0's auc: 0.641387\n",
      "[250]\tvalid_0's auc: 0.642342\n",
      "[300]\tvalid_0's auc: 0.642861\n",
      "[350]\tvalid_0's auc: 0.643395\n",
      "[400]\tvalid_0's auc: 0.643238\n",
      "[450]\tvalid_0's auc: 0.643483\n",
      "[500]\tvalid_0's auc: 0.643361\n",
      "[550]\tvalid_0's auc: 0.643248\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's auc: 0.643493\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.632548\n",
      "[100]\tvalid_0's auc: 0.636961\n",
      "[150]\tvalid_0's auc: 0.639561\n",
      "[200]\tvalid_0's auc: 0.6409\n",
      "[250]\tvalid_0's auc: 0.641606\n",
      "[300]\tvalid_0's auc: 0.642088\n",
      "[350]\tvalid_0's auc: 0.641887\n",
      "[400]\tvalid_0's auc: 0.642377\n",
      "[450]\tvalid_0's auc: 0.642771\n",
      "[500]\tvalid_0's auc: 0.64251\n",
      "[550]\tvalid_0's auc: 0.643075\n",
      "[600]\tvalid_0's auc: 0.642542\n",
      "[650]\tvalid_0's auc: 0.642402\n",
      "Early stopping, best iteration is:\n",
      "[557]\tvalid_0's auc: 0.643175\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1d27c3a41a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m                \u001b[0mclf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                clf_3.predict(X_test, raw_score=True)) / (3*n_splits)\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0my_test_model_1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0my_test_model_2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0my_test_model_3\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, pred_parameter)\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_leaf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"DataFrame.dtypes for data must be int, float or bool. Did not expect the data types in fields \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(3)\n",
    "model_scores = {}\n",
    "\n",
    "# Drop binary columns with almost all zeros. \n",
    "# Why now? Just follow along for now. We have a lot of experimentation to be done\n",
    "train = train_master.drop(['ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_13_bin'],axis=1)\n",
    "test = test_master.drop(['ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_13_bin'],axis=1)\n",
    "\n",
    "# Drop calculated features\n",
    "# But WHY??? \n",
    "# Because we are assuming that tree can generate any complicated function \n",
    "# of base features and calculated features add no more information\n",
    "# Is this assumption valid? Results will tell\n",
    "calc_columns = [s for s in list(train_master.columns.values) if '_calc' in s]\n",
    "train = train.drop(calc_columns, axis=1)  \n",
    "test = test.drop(calc_columns, axis=1)\n",
    "\n",
    "# Get categorical columns for encoding later\n",
    "categorical_columns = [s for s in list(train_master.columns.values) if '_cat' in s]\n",
    "target_column = 'target'\n",
    "\n",
    "# Replace missing values with NaN\n",
    "train = train.replace(-1, np.nan)\n",
    "test = test.replace(-1, np.nan)\n",
    "\n",
    "# Initialize DS to store validation fold predictions\n",
    "y_val_fold = np.empty(len(train))\n",
    "\n",
    "# Initialize DS to store test predictions with aggregate model and individual models\n",
    "y_test = np.zeros(len(test))\n",
    "y_test_model_1 = np.zeros(len(test))\n",
    "y_test_model_2 = np.zeros(len(test))\n",
    "y_test_model_3 = np.zeros(len(test))\n",
    "\n",
    "for fold_number, (train_ids, val_ids) in enumerate(\n",
    "    folds.split(train.drop(['id',target_column], axis=1), \n",
    "                train[target_column])):\n",
    "    \n",
    "    X = train.iloc[train_ids]\n",
    "    X_val = train.iloc[val_ids]\n",
    "    X_test = test\n",
    "    \n",
    "    # Encode categorical variables using training fold\n",
    "    encoding_dict = encode_cat_features(X, X_val, categorical_columns, target_column)\n",
    "    \n",
    "    for c, encoding in encoding_dict.items():\n",
    "        X = pd.merge(X, encoding[[c,'enc']], how='left', on=c, sort=False,suffixes=('', '_'+c))\n",
    "        X = X.drop(c, axis = 1)\n",
    "        X = X.rename(columns = {'enc':'enc_'+c})\n",
    "        \n",
    "        X_test = pd.merge(X_test, encoding[[c,'enc']], how='left', on=c, sort=False,suffixes=('', '_'+c))\n",
    "        X_test = X_test.drop(c, axis = 1)\n",
    "        X_test = X_test.rename(columns = {'enc':'enc_'+c})\n",
    "        \n",
    "        X_val = pd.merge(X_val, encoding[[c,'enc']], how='left', on=c, sort=False,suffixes=('', '_'+c))\n",
    "        X_val = X_val.drop(c, axis = 1)\n",
    "        X_val = X_val.rename(columns = {'enc':'enc_'+c})\n",
    "        \n",
    "    # Seperate target column and remove id column from all\n",
    "    y = X[target_column]\n",
    "    X = X.drop(['id',target_column], axis=1)\n",
    "    X_test = X_test.drop('id', axis=1)\n",
    "    y_val = X_val[target_column]\n",
    "    X_val = X_val.drop(['id',target_column], axis=1)\n",
    "    \n",
    "    # Upsample data in training folds\n",
    "    ids_to_duplicate = pd.Series(y == 1)\n",
    "    X = pd.concat([X, X.loc[ids_to_duplicate]], axis=0)\n",
    "    y = pd.concat([y, y.loc[ids_to_duplicate]], axis=0)\n",
    "    # Again Upsample (total increase becomes 4 times)\n",
    "    X = pd.concat([X, X.loc[ids_to_duplicate]], axis=0)\n",
    "    y = pd.concat([y, y.loc[ids_to_duplicate]], axis=0)\n",
    "    \n",
    "    # Shuffle after concatenating duplicate rows\n",
    "    # We cannot use inbuilt shuffles since both dataframes have to be shuffled in sync\n",
    "    shuffled_ids = np.arange(len(X))\n",
    "    np.random.shuffle(shuffled_ids)\n",
    "    X = X.iloc[shuffled_ids]\n",
    "    y = y.iloc[shuffled_ids]\n",
    "    \n",
    "    # Feature Selection goes here\n",
    "    # TODO\n",
    "    \n",
    "    # Define parameters of GBM as explained before for 3 trees\n",
    "    params_1 = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 1,\n",
    "        'bagging_fraction': 1,\n",
    "        'bagging_freq': 10,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    params_2 = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 2,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    params_3 = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.3,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 10,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    # Create appropriate format for training and evaluation data\n",
    "    lgb_train = lgb.Dataset(X, y)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    # Create the 3 classifiers with 1000 rounds and a window of 100 for early stopping\n",
    "    clf_1 = lgb.train(params_1,lgb_train, num_boost_round=1000,\n",
    "                      valid_sets=lgb_eval, early_stopping_rounds=100, verbose_eval=50)\n",
    "    clf_2 = lgb.train(params_2,lgb_train, num_boost_round=1000,\n",
    "                      valid_sets=lgb_eval, early_stopping_rounds=100, verbose_eval=50)\n",
    "    clf_3 = lgb.train(params_3,lgb_train, num_boost_round=1000,\n",
    "                      valid_sets=lgb_eval, early_stopping_rounds=100, verbose_eval=50)\n",
    "    \n",
    "    # Predict raw scores for validation ids\n",
    "    # At each fold, 1/10th of the training data get scores\n",
    "    y_val_fold[val_ids] = (clf_1.predict(X_val, raw_score=True)+\n",
    "                           clf_2.predict(X_val, raw_score=True)+\n",
    "                           clf_3.predict(X_val, raw_score=True)) / 3\n",
    "\n",
    "    # Predict and average over folds, raw scores for test data\n",
    "    y_test += (clf_1.predict(X_test, raw_score=True)+\n",
    "               clf_2.predict(X_test, raw_score=True)+\n",
    "               clf_3.predict(X_test, raw_score=True)) / (3*n_splits)\n",
    "    y_test_model_1 += clf_1.predict(X_test, raw_score=True) / n_splits\n",
    "    y_test_model_2 += clf_2.predict(X_test, raw_score=True) / n_splits\n",
    "    y_test_model_3 += clf_3.predict(X_test, raw_score=True) / n_splits\n",
    "    \n",
    "    # Display fold predictions\n",
    "    # Gini requires only order and therefore raw scores need not be scaled\n",
    "    print(\"Fold %2d : %.9f\" % (fold_number + 1, gini(y_val, y_val_fold[val_ids])))\n",
    "    \n",
    "# Display aggregate predictions\n",
    "# Gini requires only order and therefore raw scores need not be scaled\n",
    "print(\"Average score over all folds: %.9f\" % gini(train_master[target_column], y_val_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1d21353-bde7-4585-87f6-01b0a9696571",
    "_uuid": "dd595c4755b905ad349a6024733ef3673c441e01"
   },
   "outputs": [],
   "source": [
    "temp = y_test\n",
    "# Scale the raw scores to range [0.0, 1.0]\n",
    "temp = np.add(temp,abs(min(temp)))/max(np.add(temp,abs(min(temp))))\n",
    "\n",
    "df = pd.DataFrame(columns=['id', 'target'])\n",
    "df['id']=test_master['id']\n",
    "df['target']=temp\n",
    "df.to_csv('lgbtestwithprobs.csv', index=False, float_format=\"%.9f\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
